{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnF66Cx42S7o1riv7yZlZf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKzIEqWN35Aa",
        "outputId": "6aa7a575-4c9e-42b2-f25f-c7724a2cfb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "b7W9O4vJ4Hpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your restaurant review dataset (replace 'data.csv' with your dataset file)\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)"
      ],
      "metadata": {
        "id": "_RxM4Dhz4LqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Review'], data['Liked'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "ddO-qhXF4Qxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad the text data\n",
        "max_words = 5000  # Maximum number of words in your vocabulary\n",
        "max_sequence_length = 100  # Maximum sequence length (you can adjust this)\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n"
      ],
      "metadata": {
        "id": "9yMvqwdK4VBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels (convert labels to numerical values)\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "num_classes = len(label_encoder.classes_)\n"
      ],
      "metadata": {
        "id": "MZ14AdCG4Xdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN model\n",
        "embedding_dim = 100  # You can adjust this dimension\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(units=128))  # You can adjust the number of units\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "8QdHM_vB4aqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "I4ZoZ5oG4eJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 5  # You can adjust the number of epochs\n",
        "batch_size = 64  # You can adjust the batch size\n",
        "model.fit(X_train_pad, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_pad, y_test_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AcHQIBX4hYu",
        "outputId": "6a60bf48-2bd2-4686-cc7b-eece453d1484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "13/13 [==============================] - 4s 144ms/step - loss: 0.6980 - accuracy: 0.5312 - val_loss: 0.7138 - val_accuracy: 0.4800\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 1s 103ms/step - loss: 0.6532 - accuracy: 0.6050 - val_loss: 0.6828 - val_accuracy: 0.5750\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 1s 81ms/step - loss: 0.5227 - accuracy: 0.8938 - val_loss: 0.6821 - val_accuracy: 0.5650\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 1s 61ms/step - loss: 0.2976 - accuracy: 0.9413 - val_loss: 0.7303 - val_accuracy: 0.5800\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 1s 60ms/step - loss: 0.1084 - accuracy: 0.9787 - val_loss: 0.7865 - val_accuracy: 0.6200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c12141ad840>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = np.argmax(model.predict(X_test_pad), axis=-1)  # Convert softmax probabilities to class labels\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "precision = precision_score(y_test_encoded, y_pred, average='weighted')\n",
        "recall = recall_score(y_test_encoded, y_pred, average='weighted')\n",
        "confusion = confusion_matrix(y_test_encoded, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l1laCsC4nyZ",
        "outputId": "040e293a-1409-4d34-fcd3-bb8123f79916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('RECURRENT NEURAL NETWORK (RNN):')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Confusion Matrix:\\n\",confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGgvgxsD4sDC",
        "outputId": "2081f478-dd7a-4359-9c45-5333783e1cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RECURRENT NEURAL NETWORK (RNN):\n",
            "Accuracy: 0.62\n",
            "Precision: 0.6219871794871795\n",
            "Recall: 0.62\n",
            "Confusion Matrix:\n",
            " [[62 34]\n",
            " [42 62]]\n"
          ]
        }
      ]
    }
  ]
}